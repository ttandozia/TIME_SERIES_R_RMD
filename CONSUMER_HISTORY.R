# Packages
lista_pack2 <- c("forecast","ggplot2","urca","lmtest","dplyr","data.table","seasonal","seasonalview","zoo","stringr")
# install.packages(lista_pack2)
lapply(lista_pack2, require, character.only = TRUE)


# Data path
setwd('C:/Users/ttandozia/Desktop/CONSUMER_HISTORY')


# Dataset
study <- fread('STUDY.csv', sep = ',', colClasses = 'character', header = T)
study <- study %>% dplyr::mutate_at(vars(2:6), ~ as.numeric(str_replace(gsub(c("[$R-]"), "", .), ",", ".")))
study$Unemployment <- round(study$Unemployment,4)*100


'The time series will be generated by the column Gros Domestic Product (GDP). Also, we will try to extrapolate
with the data from the Unemployment column.

Important:
- We will create the time series ending in late 2019;

What we will have:
- The extrapolation of the expectation of GPD by it-self and with a scenario with unemployment as a predictor.'


# Generating the time series
ts_GDP <- ts(study$Gross_domestic_product_GDP, start = c(1948,1), end = c(2019,4), frequency = 4)
autoplot(ts_GDP, main = 'Gros Domestic Product')


# Mean, median, summary, length
mean(ts_GDP)
median(ts_GDP)
summary(ts_GDP)
length(ts_GDP)


# Graphics
hist(ts_GDP, main = 'Gros Domestic Product')
boxplot(ts_GDP, main = 'Gros Domestic Product')
plot(aggregate(ts_GDP, FUN=mean), main = 'Gros Domestic Product')
'FUN is the aggregation function. Softened data that is very seasonal.'


# Predictive time series model
prev <- auto.arima(ts_GDP)
print(prev$residuals) # data are per quarter in this ts


# Analyzing residuals
autoplot(prev$residuals, main = 'Residuals ARIMA GPD')
hist(prev$residuals, main = 'Residuals ARIMA GPD')
var(prev$residuals,na.rm = T) # Variance. 'na.rm' does not consider NA
mean(as.vector(prev$residuals),na.rm = T)


# Self-correlation (acf) and Partial auto-correlation (pacf)
acf(prev$residuals, na.action = na.pass, main = 'Self-correlation (ACF) Residuals ARIMA GPD') # na.action to ignore 'NA'
pacf(prev$residuals, na.action = na.pass, lag.max = 13, main = 'Partial auto-correlation (PACF) Residuals ARIMA GPD')
'Just white noise'


# Special function to check residuals in the model
checkresiduals(prev)

'ARIMA (1, 2, 2) means that this has:
* 1 auto-regressive parameter;
* 2 differentiations from the original series;
* 2 parameters of moving averages.'


# Normality test
shapiro.test(prev$residuals) # To see if are normally distributed
'The data does not come from a normal distribution'


# Stationarity test
x <- ur.kpss(ts_GDP) # This series has a tendency. Probably not stationary.
print(x) # The test is greater than 0.05. It shows us that this series is not stationary.


# Differentiation to transform from non-stationary to stationary

# Function to know how many differentiations are needed
ndiffs(ts_GDP)
'This information follows the ARIMA(1,2,2) analysis.'


# 1 differentiation
ts_GDP_1 <- diff(ts_GDP)
x <- ur.kpss(ts_GDP_1)
print(x)


# 2 differentiations
ts_GDP_2 <- diff(ts_GDP_1)
x <- ur.kpss(ts_GDP_2)
print(x)

'After 2 differentiation processes, we managed to transform it into a stationary one.'


# Visually analyzing both (original and after 2 differentiations)

split.screen( figs = c( 2, 1 ) ) # Breaks the plot screen into 2
screen(1)
plot(ts_GDP, main = 'Gros Domestic Product')
screen(2)
plot(ts_GDP_2, main = 'Gros Domestic Product | 2 differentiations')
close.screen( all = TRUE )


# Seasonality and trend of the normal series
plot(ts_GDP, main = 'Gros Domestic Product')
abline(reg=lm(ts_GDP~time(ts_GDP)), col = 'red')


# Seasonality and trend of the 2 differentiations series
plot(ts_GDP_2, main = 'Gros Domestic Product | 2 differentiations')
abline(reg=lm(ts_GDP_2~time(ts_GDP_2)), col = 'red')


# Classical decomposition of the normal series
normal <- decompose(ts_GDP)
autoplot(normal, main = 'Classical Decompose TS Gros Domestic Product')


# Classical decomposition of the 2 differentiations series
dif_2 <- decompose(ts_GDP_2)
autoplot(dif_2, main = 'Classical Decompose TS Gros Domestic Product | 2 differentiations')


# Mstl decomposition of the normal series
msap_normal <- mstl(ts_GDP)
autoplot(msap_normal, main = 'MSTL Decompose TS Gros Domestic Product')


# Mstl decomposition of the 2 differentiations series
msap_dif <- mstl(ts_GDP_2)
autoplot(msap_dif, main = 'MSTL Decompose TS Gros Domestic Product | 2 differentiations')


# Transformation
'lambda = 0, logarithmic
We will generate automatic labda'

# Normal series
lbd_normal <- BoxCox.lambda(ts_GDP)
print(lbd_normal)
ts_GDP_t <- BoxCox(ts_GDP,lambda = lbd_normal)
autoplot(ts_GDP_t, main = 'TS Gros Domestic Product | BoxCox transformation')


# 2 differentiations series
lbd_dif <- BoxCox.lambda(ts_GDP_2)
print(lbd_dif)
ts_GDP_2_t <- BoxCox(ts_GDP_2,lambda = lbd_dif)
autoplot(ts_GDP_2_t, main = 'TS Gros Domestic Product | BoxCox transformation | 2 differentiations')


split.screen( figs = c( 2, 1 ) )
screen(1)
plot(ts_GDP, main = 'Gros Domestic Product')
screen(2)
plot(ts_GDP_t, main = 'Gros Domestic Product | BoxCox')
close.screen( all = TRUE )


split.screen( figs = c( 2, 1 ) )
screen(1)
plot(ts_GDP_2, main = 'Gros Domestic Product | 2 differentiations')
screen(2)
plot(ts_GDP_2_t, main = 'Gros Domestic Product | 2 differentiations BoxCox')
close.screen( all = TRUE )


# Calculating the moving average with order 2 in the normal series
ts_GDP_t_m2 <- ma(ts_GDP_t, order = 2)
autoplot(ts_GDP_t_m2, main = 'GDP | BoxCox | moving average 2')


# calculating the moving average with order 2 in the 2 differentiations series
ts_GDP_2_t_m2 <- ma(ts_GDP_2_t, order = 2)
autoplot(ts_GDP_2_t_m2, main = 'GDP | BoxCox 2 diffs. | moving average 2')


# Again, order 12 in normal
ts_GDP_t_m12 <- ma(ts_GDP_t, order = 12)
autoplot(ts_GDP_t_m12, main = 'GDP | BoxCox | moving average 12')


# Again, order 12 in 2 differentiations series
ts_GDP_2_t_m12 <- ma(ts_GDP_2_t, order = 2)
autoplot(ts_GDP_2_t_m12, main = 'GDP | BoxCox | 2 diffs. | moving average 12')


# Data cleaning. Take outliers in the normal series
ts_GDP_t_c <- tsclean(ts_GDP_t)
autoplot(ts_GDP_t_c, main = 'GDP | BoxCox | cleaned')


# Data cleaning. Take outliers in the 2 differentiations series
ts_GDP_2_t_c <- tsclean(ts_GDP_2_t)
autoplot(ts_GDP_2_t_c, main = 'GDP | BoxCox | 2 diffs. | cleaned')


# Comparing 
plot(ts_GDP_t_c, main = 'GDP | BoxCox | cleaned')
lines(ts_GDP_t, col="red")
lines(ts_GDP_t_m2, col="blue")
lines(ts_GDP_t_m12, col="green")

# Legend
legend("topleft",legend=c("without_dif_transf_clean","Transf","Ma2","Ma12"),
       col = c("black","red","blue","green"), lty=1:2, cex=0.8)


# Comparing 
plot(ts_GDP_2_t_c, main = 'GDP | BoxCox | 2 diffs. | cleaned')
lines(ts_GDP_2_t, col="red")
lines(ts_GDP_2_t_m2, col="blue")
lines(ts_GDP_2_t_m12, col="green")

# Legend
legend("topleft",legend=c("with_dif_transf_clean","Transf","Ma2","Ma12"),
       col = c("black","red","blue","green"), lty=1:2, cex=0.8)

'PREDICTS'

# First model with ts after boxcox and cleaning process

# Train and test sets for BoxCox without differentiations
treino_bxc_cl <- window(ts_GDP_t_c, start=c(1948,1), end=c(2017,4))
teste_bxc_cl <- window(ts_GDP_t_c, start=c(2018,1), end=c(2019,4))


# ARIMA
modelo_bxc_cl <- auto.arima(treino_bxc_cl)
modelo_bxc_cl


# Predicts
prev_bxc_cl <- forecast(modelo_bxc_cl)
print(prev_bxc_cl)
autoplot(prev_bxc_cl, main = 'ARIMA BOXCOX')


# Analyzing
plot(prev_bxc_cl, main = 'ARIMA BOXCOX')
lines(prev_bxc_cl$mean, col="red")


'ACCURACY'
accuracy(ts_GDP_t_c[281:288],prev_bxc_cl$mean)
'The Mean Absolute Percent Error was 12%'


# REGRESSION WITH 1 COLUMN + TREND

# Creating ts with all features
ts_GDP_GERAL <- ts(study, start = c(1948,1), end = c(2019,4), frequency = 4)
autoplot(ts_GDP_GERAL, main = 'GDP ALL FEATURES')


# Train and test sets for BoxCox without differentiations
treino_bxc <- window(ts_GDP_t, start=c(1948,1), end=c(2017,4))
teste_bxc <- window(ts_GDP_t, start=c(2018,1), end=c(2019,4))


# Train and test sets for ts with 2 differentiations and BoxCox transformation
treino_bxc_dif <- window(ts_GDP_2_t, start=c(1948,1), end=c(2017,4))
teste_bxc_dif <- window(ts_GDP_2_t, start=c(2018,1), end=c(2019,4))


# separates the unemployment variable for the model
unemp <- as.vector(window(ts_GDP_GERAL[,c("Unemployment")],
                              start=c(1948,1), end=c(2017,4)))

unemp
'This range of the unemployment variable from 1948 to 2019 will be used in xreg
when creating the model.
Then we will extract the period from 2017 to 2019 (8 in total) to use
forecast function'


# ARIMA with unemployment used in xreg
modelo_bxc <- auto.arima(treino_bxc, xreg = unemp)
modelo_bxc


# Function to know how many differentiations the variable unemployment needs to become stationary
ndiffs(unemp)


# Differentiation
unemp_dif <- diff(unemp)
x <- ur.kpss(unemp_dif)
print(x)


# Trainning with a window in unemployment
unemp2 <- unemp_dif[3:280]
modelo_bxc_dif <- auto.arima(treino_bxc_dif, xreg = unemp2)
modelo_bxc_dif


# New data for unemployment
unemp_novo <- as.vector(window(ts_GDP_GERAL[,c("Unemployment")],
                           start=c(2018,1), end=c(2019,4)))


# Predicts
prev_bxc <- forecast(modelo_bxc, xreg = unemp_novo)
print(prev_bxc)
autoplot(prev_bxc, main = 'ARIMA BOXCOX')


prev_bxc_dif <- forecast(modelo_bxc_dif, xreg = unemp_novo)
print(prev_bxc_dif)
autoplot(prev_bxc_dif, main = 'ARIMA BOXCOX | DIFFERENTIATIONS')


# Analyzing
plot(prev_bxc, main = 'ARIMA BOXCOX')
lines(prev_bxc$mean, col="red")

plot(prev_bxc_dif, main = 'ARIMA BOXCOX | DIFFERENTIATIONS')
lines(prev_bxc_dif$mean, col="red")


'ACCURACY'
accuracy(ts_GDP_t[281:288],prev_bxc$mean)
'The Mean Absolute Percent Error was 18%'


accuracy(ts_GDP_2_t[279:286],prev_bxc_dif$mean)
'The model with the series after 2 differentiations was not efficient.'


# ARIMA AND RNN WITH 1 COLUMN + TREND

# Aggregating the unemployment column in the adjusted series
unemp <- as.ts(ts_GDP_GERAL[,6])
ts_GDP_t_un <- t(ts(rbind(ts_GDP_t,unemp)))
ts_GDP_t_un <- ts(ts_GDP_t_un, start=c(1948,1),end=c(2019,4), frequency = 4)
colnames(ts_GDP_t_un) <- c('GDP','unemp')       
autoplot(ts_GDP_t_un, main = 'GDP + UNEMP')


unemp <- as.ts(ts_GDP_GERAL[,6])
unemp <- unemp[3:288]
ts_GDP_2_t_un <- t(ts(rbind(ts_GDP_2_t,unemp)))
ts_GDP_2_t_un <- ts(ts_GDP_2_t_un, start=c(1948,1),end=c(2019,4), frequency = 4)
colnames(ts_GDP_2_t_un) <- c('GDP','unemp')       
autoplot(ts_GDP_2_t_un, main = 'GDP DIFFS. + UNEMP')


# Train and test sets
treino_bxc_un <- window(ts_GDP_t_un, start=c(1948,1), end=c(2017,4))
teste_bxc_un <- window(ts_GDP_t_un, start=c(2018,1), end=c(2019,4))

treino_bxc_dif_un <- window(ts_GDP_2_t_un, start=c(1948,1), end=c(2017,4))
teste_bxc_dif_un <- window(ts_GDP_2_t_un, start=c(2018,1), end=c(2019,4))


# Auto Arima
modelo_arima_bxc <- auto.arima(y=treino_bxc_un[,1], xreg = treino_bxc_un[,2], stepwise = F, trace = F)
modelo_arima_bxc_dif <- auto.arima(y=treino_bxc_dif_un[,1], xreg = treino_bxc_dif_un[,2], stepwise = F, trace = F)


# Predict
prev_arima_bxc <- forecast(modelo_arima_bxc, xreg = teste_bxc_un[,2])
prev_arima_bxc_dif <- forecast(modelo_bxc_dif, xreg = teste_bxc_dif_un[,2])


# Plot
plot(treino_bxc_un[,1], main = 'ARIMA BOXCOX + UNEMP')
lines(prev_arima_bxc$mean, col="red")

plot(treino_bxc_dif_un[,1], main = 'ARIMA BOXCOX DIFFS. + UNEMP')
lines(prev_arima_bxc_dif$mean, col="red")


# Accuracy
accuracy(prev_arima_bxc$mean,teste_bxc_un[,1])
accuracy(prev_arima_bxc_dif$mean,teste_bxc_dif_un[,1])


# RNN
modelo_rnn_bxc <- nnetar(y = treino_bxc_un[,1], xreg = treino_bxc_un[,2])
modelo_rnn_bxc_dif <- nnetar(y = treino_bxc_dif_un[,1], xreg = treino_bxc_dif_un[,2])


# Predict
prev_rnn_bxc <- forecast(modelo_rnn_bxc, xreg = teste_bxc_un[,2])
prev_rnn_bxc_dif <- forecast(modelo_rnn_bxc_dif, xreg = teste_bxc_dif_un[,2])


# Plot
autoplot(prev_rnn_bxc, main = 'RNN BOXCOX + UNEMP')
autoplot(prev_rnn_bxc_dif)


# Accuray
accuracy(prev_rnn_bxc$mean,teste_bxc_un[,1])
accuracy(prev_rnn_bxc_dif$mean,teste_bxc_dif_un[,1])


# Plot
plot(ts_GDP_t_un[,1], main = 'CPMPARING MODELS')
lines(prev_arima_bxc$mean, col="blue")
lines(prev_rnn_bxc$mean, col="red")
legend("topleft",legend=c("ARIMA","RNN"),
       col = c("blue","red"), lty=1:2, cex=0.8)


plot(ts_GDP_2_t_un[,1], main = 'COMPARING MODELS DIFFS.')
lines(prev_arima_bxc_dif$mean, col="blue")
lines(prev_rnn_bxc_dif$mean, col="red")
legend("topleft",legend=c("ARIMA","RNN"),
       col = c("blue","red"), lty=1:2, cex=0.8)


# Regression for time series (TSLM)

# Adjusting the studys for the model
gdp_treino_bxc <- treino_bxc_un[,1]
gdp_teste_bxc <- teste_bxc_un[,1]

gdp_treino_bxc_dif <- treino_bxc_dif_un[,1]
gdp_teste_bxc_dif <- teste_bxc_dif_un[,1]

unemp_treino <- ts(ts_GDP_GERAL[1:280,6], start=c(1948,1), end=c(2017,4), frequency = 4)
unemp_teste <- ts(ts_GDP_GERAL[281:288,6], start=c(2018,1), end=c(2019,4), frequency = 4)


# Models
modelo_reg_bxc <- tslm(gdp_treino_bxc ~ trend + season + unemp_treino)
modelo_reg_bxc_dif <- tslm(gdp_treino_bxc_dif ~ trend + season + unemp_treino)


# Predict
prev_reg_bxc <- forecast(modelo_reg_bxc, newdata = data.frame(unemp_treino = unemp_teste))
prev_reg_bxc_dif <- forecast(modelo_reg_bxc_dif, newdata = data.frame(unemp_treino = unemp_teste))


# Accuracy
accuracy(prev_reg_bxc$mean,gdp_teste_bxc)
accuracy(prev_reg_bxc_dif$mean,gdp_teste_bxc_dif)


# Plot
plot(ts_GDP_t_un[,1], main = 'COMPARING MODELS')
lines(prev_arima_bxc$mean, col="blue")
lines(prev_rnn_bxc$mean, col="red")
lines(prev_reg_bxc$mean, col="green")
legend("topleft",legend=c("ARIMA","RNN", "REGRESSION"),
       col = c("blue","red", "green"), lty=1:2, cex=0.8)


plot(ts_GDP_2_t_un[,1], main = 'COMPARING MODELS DIFFS.')
lines(prev_arima_bxc_dif$mean, col="blue")
lines(prev_rnn_bxc_dif$mean, col="red")
lines(prev_reg_bxc_dif$mean, col="green")
legend("topleft",legend=c("ARIMA","RNN", "REGRESSION"),
       col = c("blue","red", "green"), lty=1:2, cex=0.8)


# CONCLUSION
"The best model was a Forecast, applied in ARIMA (2,2,1),
built with a set of data after BoxCox transformation and
process of cleaning outliers. Below is a model's summary"

# Predicts
autoplot(prev_bxc_cl, main = 'ARIMA BOXCOX')

# Analyzing
plot(prev_bxc_cl, main = 'ARIMA BOXCOX')
lines(prev_bxc_cl$mean, col="red")


'ACCURACY'
accuracy(ts_GDP_t_c[281:288],prev_bxc_cl$mean)
'The Mean Absolute Percent Error was 12%'

rm(list = ls())
gc()

 